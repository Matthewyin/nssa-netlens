from .tshark import tshark
from collections import defaultdict
import math
import os


class MultiPcapAnalyzer:
    def __init__(self):
        pass

    def extract_signatures(self, filepath: str):
        if not os.path.exists(filepath):
            raise FileNotFoundError(f"File not found: {filepath}")

        # Extract Seq, Ack, Len, DstPort, Time
        # Only TCP packets with payload are reliable for correlation (SYN/ACKs might be generated by middleboxes)
        # But let's include all TCP for completeness.
        fields = [
            "frame.time_epoch",
            "tcp.seq",
            "tcp.ack",
            "tcp.len",
            "tcp.dstport",
            "ip.dst",
            "frame.number",
        ]

        signatures = []
        try:
            for row in tshark.stream_fields(filepath, fields, display_filter="tcp"):
                signatures.append(
                    {
                        "ts": float(row.get("frame.time_epoch", 0)),
                        "seq": row.get("tcp.seq"),
                        "ack": row.get("tcp.ack"),
                        "len": row.get("tcp.len", "0"),
                        "dst_port": row.get("tcp.dstport"),
                        "dst_ip": row.get("ip.dst"),
                        "frame": row.get("frame.number"),
                    }
                )
        except Exception as e:
            print(f"Error extracting signatures from {filepath}: {e}")

        return signatures

    def correlate(self, file_a: str, file_b: str):
        # 1. Extract
        sigs_a = self.extract_signatures(file_a)
        sigs_b = self.extract_signatures(file_b)

        # 2. Index File B
        # Key = (Seq, Ack, Len, DstPort) -> List of packets (sorted by time)
        # We include DstPort to disambiguate flows, assuming NAT preserves Dest Port (usually true for outgoing).
        # DstIP might change (DNAT), SrcIP matches definitely change (SNAT).
        index_b = defaultdict(list)
        for p in sigs_b:
            key = (p["seq"], p["ack"], p["len"], p["dst_port"])
            index_b[key].append(p)

        # 3. Match
        matches = []
        lost_a = []

        # Time Offset Calculation
        # We use a sliding window or RANSAC to find best offset, but here we use simple median of first 10 matches
        offsets = []

        # Temporary match to find offset
        temp_index = {k: list(v) for k, v in index_b.items()}
        for p_a in sigs_a[:100]:  # Look at first 100 packets
            key = (p_a["seq"], p_a["ack"], p_a["len"], p_a["dst_port"])
            candidates = temp_index.get(key)
            if candidates:
                # Assume the first one is the match for offset calculation
                p_b = candidates.pop(0)
                offsets.append(p_b["ts"] - p_a["ts"])
                if len(offsets) > 10:
                    break

        if offsets:
            offsets.sort()
            time_offset = offsets[len(offsets) // 2]  # Median
        else:
            time_offset = 0.0

        # Real Matching
        for p_a in sigs_a:
            key = (p_a["seq"], p_a["ack"], p_a["len"], p_a["dst_port"])
            candidates = index_b.get(key)

            if candidates:
                # Find the candidate closest in time (accounting for offset)
                # Filter candidates that are plausible (e.g. +/- 5 seconds)
                best_match = None
                best_idx = -1
                min_diff = float("inf")

                for idx, p_b in enumerate(candidates):
                    diff = abs(p_b["ts"] - (p_a["ts"] + time_offset))
                    if diff < min_diff and diff < 2.0:  # 2 second window
                        min_diff = diff
                        best_match = p_b
                        best_idx = idx

                if best_match:
                    matches.append(
                        {
                            "frame_a": p_a["frame"],
                            "frame_b": best_match["frame"],
                            "ts_a": p_a["ts"],
                            "ts_b": best_match["ts"],
                            "latency": best_match["ts"]
                            - p_a["ts"],  # Absolute latency (clock diff included)
                        }
                    )
                    # Consume the match
                    candidates.pop(best_idx)
                else:
                    lost_a.append(p_a["frame"])
            else:
                lost_a.append(p_a["frame"])

        return {
            "matches": matches,
            "lost_in_b_count": len(lost_a),
            "lost_frames_a": lost_a[:100],  # Limit output
            "total_a": len(sigs_a),
            "total_b": len(sigs_b),
            "estimated_time_offset": time_offset,
        }
